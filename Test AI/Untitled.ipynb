{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0657d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4774 - accuracy: 0.7500 - val_loss: 0.9443 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4186 - accuracy: 0.7500 - val_loss: 0.9824 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3663 - accuracy: 1.0000 - val_loss: 1.0215 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3213 - accuracy: 1.0000 - val_loss: 1.0628 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2817 - accuracy: 1.0000 - val_loss: 1.1051 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2464 - accuracy: 1.0000 - val_loss: 1.1478 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.1935 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1895 - accuracy: 1.0000 - val_loss: 1.2433 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1666 - accuracy: 1.0000 - val_loss: 1.2960 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.1467 - accuracy: 1.0000 - val_loss: 1.3485 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1298 - accuracy: 1.0000 - val_loss: 1.4022 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1152 - accuracy: 1.0000 - val_loss: 1.4579 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1020 - accuracy: 1.0000 - val_loss: 1.5165 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0900 - accuracy: 1.0000 - val_loss: 1.5743 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0792 - accuracy: 1.0000 - val_loss: 1.6315 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0696 - accuracy: 1.0000 - val_loss: 1.6885 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0611 - accuracy: 1.0000 - val_loss: 1.7454 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 1.8009 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 1.8544 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 1.9045 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 1.9512 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 1.9954 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 2.0370 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 2.0811 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 2.1249 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 1.4266 - accuracy: 0.2833\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.3765 - accuracy: 0.3500\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.3374 - accuracy: 0.4500\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.3087 - accuracy: 0.4500\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2828 - accuracy: 0.5333\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2609 - accuracy: 0.4500\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2380 - accuracy: 0.4333\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.2157 - accuracy: 0.4333\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1951 - accuracy: 0.4500\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.1729 - accuracy: 0.4667\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1509 - accuracy: 0.4667\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.1291 - accuracy: 0.5333\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.1057 - accuracy: 0.5500\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0835 - accuracy: 0.5667\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.0598 - accuracy: 0.5833\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.0351 - accuracy: 0.6000\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0107 - accuracy: 0.6333\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.9846 - accuracy: 0.6500\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.9595 - accuracy: 0.6667\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.9361 - accuracy: 0.7333\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.9094 - accuracy: 0.7500\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8865 - accuracy: 0.7500\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8601 - accuracy: 0.7500\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8368 - accuracy: 0.7667\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.8133 - accuracy: 0.7667\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7896 - accuracy: 0.7667\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7662 - accuracy: 0.7667\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7451 - accuracy: 0.8167\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7258 - accuracy: 0.8167\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7033 - accuracy: 0.8167\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6842 - accuracy: 0.8333\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6640 - accuracy: 0.8333\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6467 - accuracy: 0.8333\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6315 - accuracy: 0.8333\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6115 - accuracy: 0.8333\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5952 - accuracy: 0.8333\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5809 - accuracy: 0.8500\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5651 - accuracy: 0.8667\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5513 - accuracy: 0.8667\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5382 - accuracy: 0.8667\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5252 - accuracy: 0.8667\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5111 - accuracy: 0.8667\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4986 - accuracy: 0.8667\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.4877 - accuracy: 0.8667\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4760 - accuracy: 0.8667\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4628 - accuracy: 0.8667\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.4520 - accuracy: 0.8667\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4408 - accuracy: 0.8833\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4308 - accuracy: 0.8833\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4211 - accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7/7 [==============================] - 2s 3ms/step - loss: 1.3795 - accuracy: 0.2500\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.3545 - accuracy: 0.5500\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.3317 - accuracy: 0.8450\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.3108 - accuracy: 0.7550\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2967 - accuracy: 0.3400\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2753 - accuracy: 0.6550\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2505 - accuracy: 0.8000\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2247 - accuracy: 0.9000\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1967 - accuracy: 0.9200\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.1617 - accuracy: 0.8850\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1274 - accuracy: 0.9000\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0877 - accuracy: 0.9150\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0512 - accuracy: 0.9750\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.0040 - accuracy: 0.9850\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.9560 - accuracy: 0.9750\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.9122 - accuracy: 0.9500\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.8586 - accuracy: 0.9750\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.8080 - accuracy: 0.9850\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7559 - accuracy: 0.9850\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7067 - accuracy: 0.9850\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6564 - accuracy: 0.9900\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6146 - accuracy: 0.9900\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5697 - accuracy: 0.9900\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5243 - accuracy: 0.9850\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4804 - accuracy: 0.9900\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.9900\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.9900\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3832 - accuracy: 0.9950\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3541 - accuracy: 0.9900\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.9900\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3040 - accuracy: 0.9900\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2825 - accuracy: 0.9900\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2634 - accuracy: 0.9900\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.9900\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2310 - accuracy: 0.9900\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2162 - accuracy: 0.9900\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2028 - accuracy: 0.9900\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1902 - accuracy: 0.9900\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1796 - accuracy: 0.9900\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1684 - accuracy: 0.9900\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1598 - accuracy: 0.9900\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1523 - accuracy: 0.9900\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1425 - accuracy: 0.9900\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1360 - accuracy: 0.9900\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1284 - accuracy: 0.9900\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1226 - accuracy: 0.9900\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1159 - accuracy: 0.9900\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1103 - accuracy: 0.9900\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1067 - accuracy: 0.9900\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1031 - accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "1/2 [==============>...............] - ETA: 1s - loss: 1.3894 - accuracy: 0.3750"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 12\n  y sizes: 0\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 151\u001b[0m\n\u001b[1;32m    148\u001b[0m model_combined\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# Train the model using the concatenated output of the parallel AIs and the third dataset\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m model_combined\u001b[38;5;241m.\u001b[39mfit(combined_output[:min_rows], y_data_3_encoded[:min_rows], epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Save the output of the final AI to CSV\u001b[39;00m\n\u001b[1;32m    154\u001b[0m final_output \u001b[38;5;241m=\u001b[39m model_combined\u001b[38;5;241m.\u001b[39mpredict(combined_output)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1960\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1953\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1954\u001b[0m         label,\n\u001b[1;32m   1955\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   1956\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m   1957\u001b[0m         ),\n\u001b[1;32m   1958\u001b[0m     )\n\u001b[1;32m   1959\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1960\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 12\n  y sizes: 0\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the Generic Dataset\n",
    "generic_dataset = pd.read_csv(\"Generic_Dataset.csv\")\n",
    "\n",
    "# Preprocess Generic Dataset\n",
    "X_generic = generic_dataset.iloc[:, :20].values\n",
    "y_generic = generic_dataset.iloc[:, 20].values\n",
    "\n",
    "# Encode labels\n",
    "label_encoder_generic = LabelEncoder()\n",
    "y_generic_encoded = label_encoder_generic.fit_transform(y_generic)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_generic_train, X_generic_test, y_generic_train, y_generic_test = train_test_split(\n",
    "    X_generic, y_generic_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Build and train the first AI model\n",
    "model_generic = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(20,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')  # Adjust the number of classes\n",
    "])\n",
    "\n",
    "model_generic.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_generic.fit(X_generic_train, y_generic_train, epochs=25, validation_data=(X_generic_test, y_generic_test))\n",
    "\n",
    "# Save the model for future use\n",
    "model_generic.save(\"model_generic.h5\")\n",
    "\n",
    "# Load the first dataset for parallel AI 1\n",
    "data_1 = pd.read_csv(\"data_1.csv\")\n",
    "\n",
    "# Preprocess data_1\n",
    "X_data_1 = data_1.iloc[:, :14].values\n",
    "y_data_1 = data_1.iloc[:, 14].values\n",
    "\n",
    "# Encode labels if needed\n",
    "label_encoder_data_1 = LabelEncoder()\n",
    "y_data_1_encoded = label_encoder_data_1.fit_transform(y_data_1)\n",
    "\n",
    "# Build and train the first parallel AI model\n",
    "model_parallel_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(14,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')  # Adjust the number of classes\n",
    "])\n",
    "\n",
    "model_parallel_1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_parallel_1.fit(X_data_1, y_data_1_encoded, epochs=50)\n",
    "\n",
    "# Save the model for future use\n",
    "model_parallel_1.save(\"model_parallel_1.h5\")\n",
    "\n",
    "# Load the second dataset for parallel AI 2\n",
    "data_2 = pd.read_csv(\"data_2.csv\")\n",
    "\n",
    "# Preprocess data_2\n",
    "X_data_2 = data_2.iloc[:, :5].values\n",
    "y_data_2 = data_2.iloc[:, 5].values\n",
    "\n",
    "# Encode labels if needed\n",
    "label_encoder_data_2 = LabelEncoder()\n",
    "y_data_2_encoded = label_encoder_data_2.fit_transform(y_data_2)\n",
    "\n",
    "# Build and train the second parallel AI model\n",
    "model_parallel_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(5,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')  # Adjust the number of classes\n",
    "])\n",
    "\n",
    "model_parallel_2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_parallel_2.fit(X_data_2, y_data_2_encoded, epochs=50)\n",
    "\n",
    "# Save the model for future use\n",
    "model_parallel_2.save(\"model_parallel_2.h5\")\n",
    "\n",
    "# Combine the outputs of parallel AI 1 and AI 2 for the third AI\n",
    "output_parallel_1 = model_parallel_1.predict(X_data_1)\n",
    "output_parallel_2 = model_parallel_2.predict(X_data_2)\n",
    "\n",
    "# Choose the minimum number of rows for concatenation\n",
    "min_rows = min(output_parallel_1.shape[0], output_parallel_2.shape[0])\n",
    "\n",
    "# Subset the outputs to have the same number of rows\n",
    "output_parallel_1 = output_parallel_1[:min_rows]\n",
    "output_parallel_2 = output_parallel_2[:min_rows]\n",
    "\n",
    "# Concatenate the outputs\n",
    "combined_output = tf.keras.layers.Concatenate()([output_parallel_1, output_parallel_2])\n",
    "\n",
    "# Convert to Pandas DataFrames\n",
    "output_df1 = pd.DataFrame(output_parallel_1)\n",
    "output_df2 = pd.DataFrame(output_parallel_2)\n",
    "\n",
    "# Save combined outputs to CSV\n",
    "output_df1.to_csv(\"data_watch1.csv\", index=False)\n",
    "output_df2.to_csv(\"data_watch2.csv\", index=False)\n",
    "\n",
    "# Convert parallel AI 1 output to a single column (scaling down)\n",
    "scaled_output_parallel_1 = output_parallel_1.argmax(axis=1)\n",
    "\n",
    "# Convert parallel AI 2 output to a single column (scaling down)\n",
    "scaled_output_parallel_2 = output_parallel_2.argmax(axis=1)\n",
    "\n",
    "# Save scaled outputs along with labels to CSV\n",
    "scaled_output_df1 = pd.DataFrame({'label': y_data_1_encoded[:min_rows], 'scaled_output': scaled_output_parallel_1})\n",
    "scaled_output_df1.to_csv(\"scaled_output1.csv\", index=False)\n",
    "\n",
    "scaled_output_df2 = pd.DataFrame({'label': y_data_2_encoded[:min_rows], 'scaled_output': scaled_output_parallel_2})\n",
    "scaled_output_df2.to_csv(\"scaled_output2.csv\", index=False)\n",
    "\n",
    "# Save the combined output to CSV\n",
    "combined_output_df = pd.DataFrame(combined_output.numpy())\n",
    "combined_output_df.to_csv(\"combined_output.csv\", index=False)\n",
    "\n",
    "# Define num_classes_data_3 after combining outputs\n",
    "num_classes_data_3 = 4  # Replace with the actual number of classes for the third dataset\n",
    "\n",
    "# Build and train the third AI model\n",
    "model_combined = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(combined_output.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes_data_3, activation='softmax')  # Adjust the number of classes\n",
    "])\n",
    "\n",
    "# Load the third dataset for the final AI\n",
    "data_3 = pd.read_csv(\"generated_data1.csv\")\n",
    "\n",
    "# Preprocess data_3\n",
    "X_data_3 = data_3.iloc[:, :-1].values\n",
    "y_data_3 = data_3.iloc[:, -1].values\n",
    "\n",
    "# Encode labels if needed\n",
    "label_encoder_data_3 = LabelEncoder()\n",
    "y_data_3_encoded = label_encoder_data_3.fit_transform(y_data_3)\n",
    "\n",
    "# Compile the model\n",
    "model_combined.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using the concatenated output of the parallel AIs and the third dataset\n",
    "model_combined.fit(combined_output, y_data_3_encoded[:min_rows], epochs=100, validation_split=0.2)\n",
    "\n",
    "# Save the output of the final AI to CSV\n",
    "final_output = model_combined.predict(combined_output)\n",
    "final_output_df = pd.DataFrame(final_output)\n",
    "final_output_df.to_csv(\"final_output.csv\", index=False)  # Save final output to \"final_output.csv\"\n",
    "\n",
    "# Save the model for future use\n",
    "model_combined.save(\"model_combined.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09befb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes - combined_output: (60, 8) y_data_3_encoded: (48,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes - combined_output:\", combined_output.shape, \"y_data_3_encoded:\", y_data_3_encoded[:min_rows].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f7ffd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_3_encoded[:min_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e17af3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_3_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14e51b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.96010265e-02, 6.75910175e-01, 2.68572897e-01, 3.59159559e-02,\n",
       "        5.91505915e-02, 9.38867629e-01, 6.48360641e-04, 1.33345148e-03],\n",
       "       [1.18282018e-02, 5.31453252e-01, 4.24060792e-01, 3.26577649e-02,\n",
       "        1.91286206e-01, 7.67947733e-01, 2.40655411e-02, 1.67004392e-02],\n",
       "       [1.35117145e-02, 6.43741369e-01, 3.20517898e-01, 2.22289786e-02,\n",
       "        1.42903477e-01, 8.48916709e-01, 4.13357839e-03, 4.04621195e-03],\n",
       "       [6.48885791e-04, 8.02819729e-01, 1.95927531e-01, 6.03829511e-04,\n",
       "        2.73285266e-02, 9.69007432e-01, 2.13875226e-03, 1.52527692e-03],\n",
       "       [2.19526468e-03, 5.58309793e-01, 4.36713278e-01, 2.78157671e-03,\n",
       "        2.16302633e-01, 7.70959079e-01, 1.18373113e-03, 1.15545187e-02],\n",
       "       [2.96774809e-03, 8.01086545e-01, 1.92909598e-01, 3.03610181e-03,\n",
       "        8.60853493e-02, 8.34195554e-01, 6.39602020e-02, 1.57589857e-02],\n",
       "       [1.51705847e-03, 8.17519248e-01, 1.77347064e-01, 3.61656561e-03,\n",
       "        2.29085252e-01, 7.36757815e-01, 9.63932928e-03, 2.45176349e-02],\n",
       "       [3.07777822e-02, 2.33360436e-02, 6.08909249e-01, 3.36977005e-01,\n",
       "        2.19458818e-01, 7.78361440e-01, 1.68138402e-04, 2.01159925e-03],\n",
       "       [1.71867795e-02, 7.59928972e-02, 7.50874698e-01, 1.55945659e-01,\n",
       "        8.95730257e-02, 8.62413287e-01, 3.97166051e-02, 8.29706248e-03],\n",
       "       [3.69187095e-03, 7.12898374e-01, 2.79349655e-01, 4.06000111e-03,\n",
       "        1.61867395e-01, 8.35166931e-01, 1.01078674e-03, 1.95487868e-03],\n",
       "       [1.82696879e-02, 9.18328017e-02, 7.79282928e-01, 1.10614538e-01,\n",
       "        8.29129890e-02, 9.09241676e-01, 2.40254612e-03, 5.44274645e-03],\n",
       "       [3.66395079e-02, 2.44421169e-01, 6.24329865e-01, 9.46093947e-02,\n",
       "        2.28758398e-02, 9.67806399e-01, 7.53818918e-03, 1.77955907e-03],\n",
       "       [1.40922889e-01, 1.04168937e-01, 5.63654542e-01, 1.91253573e-01,\n",
       "        1.32291004e-01, 8.22529435e-01, 1.37821995e-02, 3.13974023e-02],\n",
       "       [1.82302911e-02, 4.05723780e-01, 5.61747432e-01, 1.42984688e-02,\n",
       "        2.52615660e-01, 7.19136238e-01, 6.61393907e-03, 2.16340516e-02],\n",
       "       [2.81951157e-03, 4.59885865e-01, 5.34866154e-01, 2.42854352e-03,\n",
       "        6.62297979e-02, 9.26054537e-01, 2.71625421e-03, 4.99930419e-03],\n",
       "       [6.32478856e-04, 7.95158893e-02, 9.18266118e-01, 1.58556341e-03,\n",
       "        3.39143187e-01, 6.21819794e-01, 5.02301892e-03, 3.40139866e-02],\n",
       "       [2.83852965e-03, 5.46718180e-01, 4.46574360e-01, 3.86888254e-03,\n",
       "        3.38998228e-01, 6.36013448e-01, 2.40557035e-03, 2.25827768e-02],\n",
       "       [1.71135354e-03, 5.07127941e-01, 4.89101350e-01, 2.05940683e-03,\n",
       "        4.58578244e-02, 9.52113330e-01, 8.11364211e-04, 1.21739344e-03],\n",
       "       [9.91405174e-03, 7.03965873e-02, 9.13689852e-01, 5.99943753e-03,\n",
       "        1.64809436e-01, 7.96127856e-01, 6.70750253e-03, 3.23552229e-02],\n",
       "       [4.88707200e-02, 2.88191676e-01, 5.56328952e-01, 1.06608793e-01,\n",
       "        4.61614095e-02, 9.40089703e-01, 5.68570429e-03, 8.06315150e-03],\n",
       "       [1.91640463e-02, 7.50912488e-01, 1.88381493e-01, 4.15419787e-02,\n",
       "        9.93883386e-02, 8.86945367e-01, 4.60116146e-03, 9.06514749e-03],\n",
       "       [1.06353723e-02, 6.82713926e-01, 2.94512987e-01, 1.21377371e-02,\n",
       "        1.35255247e-01, 8.21998775e-01, 1.10319778e-02, 3.17140035e-02],\n",
       "       [1.53568313e-02, 4.25528079e-01, 5.11643767e-01, 4.74712290e-02,\n",
       "        2.50890851e-01, 7.42676497e-01, 1.40162837e-03, 5.03101666e-03],\n",
       "       [5.56515623e-03, 2.18284488e-01, 7.72496283e-01, 3.65398661e-03,\n",
       "        7.15350881e-02, 9.18199420e-01, 5.64108323e-03, 4.62442124e-03],\n",
       "       [2.74269711e-02, 7.22839475e-01, 2.28163972e-01, 2.15695724e-02,\n",
       "        1.35094240e-01, 8.63414884e-01, 4.45385347e-04, 1.04539678e-03],\n",
       "       [1.49957985e-02, 3.87177169e-01, 5.62446654e-01, 3.53803262e-02,\n",
       "        1.30304337e-01, 8.64078879e-01, 2.77279597e-03, 2.84401490e-03],\n",
       "       [1.00735528e-02, 6.73671007e-01, 2.97420055e-01, 1.88354384e-02,\n",
       "        7.97284693e-02, 9.14399445e-01, 8.66893854e-04, 5.00514172e-03],\n",
       "       [6.96977368e-03, 7.15295553e-01, 2.69576997e-01, 8.15761182e-03,\n",
       "        1.62506655e-01, 7.90231407e-01, 1.75291486e-02, 2.97327973e-02],\n",
       "       [9.93739441e-03, 7.16389954e-01, 2.62710810e-01, 1.09619042e-02,\n",
       "        2.25557890e-02, 9.76635695e-01, 4.46938328e-04, 3.61524464e-04],\n",
       "       [4.85676480e-03, 6.93915009e-01, 2.95341820e-01, 5.88644249e-03,\n",
       "        1.51388109e-01, 8.39435637e-01, 1.04157033e-03, 8.13475437e-03],\n",
       "       [2.60093182e-01, 3.45067643e-02, 6.41263485e-01, 6.41366243e-02,\n",
       "        7.68625587e-02, 9.21885967e-01, 2.59898079e-04, 9.91592533e-04],\n",
       "       [4.35894094e-02, 8.83264095e-03, 8.06592226e-01, 1.40985787e-01,\n",
       "        3.79591808e-02, 9.48551357e-01, 9.51215066e-03, 3.97722004e-03],\n",
       "       [3.68162729e-02, 7.68076107e-02, 8.39748263e-01, 4.66278382e-02,\n",
       "        4.64682654e-02, 9.29498971e-01, 1.31447641e-02, 1.08879283e-02],\n",
       "       [5.59029263e-03, 3.44108701e-01, 6.44784629e-01, 5.51637635e-03,\n",
       "        1.44090801e-01, 8.54072869e-01, 3.97047232e-04, 1.43914996e-03],\n",
       "       [2.75112074e-02, 1.52556688e-01, 7.64937997e-01, 5.49940504e-02,\n",
       "        5.92744708e-01, 3.94812524e-01, 5.47139731e-04, 1.18956026e-02],\n",
       "       [4.00149869e-03, 3.39380503e-02, 9.34765339e-01, 2.72951238e-02,\n",
       "        4.31182273e-02, 9.51083958e-01, 3.20510124e-03, 2.59268167e-03],\n",
       "       [1.51096806e-02, 5.51381009e-03, 3.57669532e-01, 6.21706963e-01,\n",
       "        2.36447990e-01, 7.59393096e-01, 6.31445204e-04, 3.52744129e-03],\n",
       "       [4.86314110e-02, 4.63738799e-01, 3.54255259e-01, 1.33374527e-01,\n",
       "        2.30452821e-01, 6.16411328e-01, 6.33487552e-02, 8.97871256e-02],\n",
       "       [2.75374651e-01, 1.18362941e-02, 1.15227178e-01, 5.97561836e-01,\n",
       "        4.49374840e-02, 9.50258195e-01, 2.80215242e-03, 2.00211629e-03],\n",
       "       [3.79060134e-02, 2.44025397e-03, 1.60786256e-01, 7.98867404e-01,\n",
       "        6.13460660e-01, 3.50320131e-01, 1.15468341e-03, 3.50645296e-02],\n",
       "       [6.67232201e-02, 1.83933061e-02, 2.27367625e-01, 6.87515855e-01,\n",
       "        1.79105863e-01, 8.14343214e-01, 2.93591467e-04, 6.25742134e-03],\n",
       "       [1.41289886e-02, 5.54819545e-03, 1.85143620e-01, 7.95179069e-01,\n",
       "        1.31799886e-02, 9.80115652e-01, 5.29436581e-03, 1.41012261e-03],\n",
       "       [6.60464913e-02, 1.01364311e-02, 1.20656766e-01, 8.03160310e-01,\n",
       "        6.17407449e-02, 9.30233181e-01, 1.63092534e-03, 6.39514904e-03],\n",
       "       [1.64548144e-01, 3.75024937e-02, 1.64077267e-01, 6.33872092e-01,\n",
       "        1.09161668e-01, 8.88309240e-01, 1.05957105e-03, 1.46942120e-03],\n",
       "       [1.53408855e-01, 9.87859815e-03, 1.61366358e-01, 6.75346255e-01,\n",
       "        1.28290311e-01, 7.57759809e-01, 7.64274746e-02, 3.75223681e-02],\n",
       "       [3.70638887e-03, 8.46219599e-01, 1.47268444e-01, 2.80551356e-03,\n",
       "        9.28252377e-03, 9.87467706e-01, 2.79981061e-03, 4.49871412e-04],\n",
       "       [5.81963686e-03, 2.34468989e-02, 7.01630533e-01, 2.69102812e-01,\n",
       "        8.01417977e-02, 8.62354815e-01, 3.45170610e-02, 2.29861941e-02],\n",
       "       [1.19836023e-02, 7.36490190e-01, 2.33496666e-01, 1.80296302e-02,\n",
       "        3.55428681e-02, 9.56369758e-01, 3.54233640e-03, 4.54499805e-03],\n",
       "       [4.05195467e-02, 1.33768301e-02, 7.55150691e-02, 8.70588541e-01,\n",
       "        2.09782980e-02, 9.78155792e-01, 4.63811564e-04, 4.01991740e-04],\n",
       "       [1.94963580e-03, 5.89446366e-01, 4.06169206e-01, 2.43473798e-03,\n",
       "        5.06193601e-02, 9.48355794e-01, 2.53103557e-04, 7.71665771e-04],\n",
       "       [3.94609384e-03, 6.84585154e-01, 3.01572740e-01, 9.89593845e-03,\n",
       "        8.22633877e-02, 1.89301614e-02, 1.61940865e-02, 8.82612467e-01],\n",
       "       [1.21836197e-02, 7.78961973e-03, 8.22030187e-01, 1.57996491e-01,\n",
       "        4.99385148e-02, 3.28255049e-03, 2.79908422e-02, 9.18788016e-01],\n",
       "       [2.58888071e-03, 1.48769587e-01, 8.35783839e-01, 1.28577631e-02,\n",
       "        9.52653065e-02, 9.53243859e-03, 2.69475579e-02, 8.68254662e-01],\n",
       "       [4.97456752e-02, 6.93156430e-03, 1.39835119e-01, 8.03487599e-01,\n",
       "        5.97824790e-02, 1.93791110e-02, 2.74688043e-02, 8.93369555e-01],\n",
       "       [2.13889822e-01, 1.41228810e-02, 2.29596570e-01, 5.42390764e-01,\n",
       "        4.48075682e-02, 2.46887002e-03, 3.50228511e-03, 9.49221253e-01],\n",
       "       [8.45210016e-01, 5.79406554e-03, 8.72730762e-02, 6.17227629e-02,\n",
       "        2.38137208e-02, 3.67403706e-03, 7.58046061e-02, 8.96707654e-01],\n",
       "       [5.71949780e-01, 4.99168970e-03, 1.69608712e-01, 2.53449708e-01,\n",
       "        2.64887549e-02, 1.85846991e-03, 1.42413890e-02, 9.57411408e-01],\n",
       "       [8.94472599e-01, 5.58219338e-03, 5.57853058e-02, 4.41599637e-02,\n",
       "        2.07595959e-01, 1.12976823e-02, 2.71926145e-03, 7.78387129e-01],\n",
       "       [6.00348055e-01, 1.45803904e-03, 8.00155625e-02, 3.18178326e-01,\n",
       "        4.55894805e-02, 6.93222787e-03, 8.59417021e-02, 8.61536682e-01],\n",
       "       [8.16054106e-01, 2.67854030e-03, 3.50293666e-02, 1.46237895e-01,\n",
       "        1.60054088e-01, 1.63209904e-02, 1.81138758e-02, 8.05511057e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7eb7d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Predicted Labels - Generic AI: ['Engineering']\n",
      "Predicted Labels - Parallel AI 1: ['Electronics and Communication Engineering']\n",
      "Predicted Labels - Parallel AI 2: ['Computer Science and Engineering (including specializations) / Information Technology']\n",
      "Predicted Labels - Combined AI: ['Electronics and Communication Engineering']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the input data for prediction\n",
    "input_data_generic = [2, 3, 3, 0, 2, 0, 2, 1, 2, 0, 1, 2, 0, 0, 2, 0, 0, 2, 1, 0]\n",
    "input_data_parallel_1 = [0, 0.66, 0, 0, 0, 0, 0.25, 0, 0, 0.5, 0, 0.25, 0, 0]\n",
    "input_data_parallel_2 = [0.706181, 0.604714, 0.528406, 0.557752, 0.315469]\n",
    "\n",
    "# No need to preprocess input data for lists, as they are not Pandas DataFrames\n",
    "\n",
    "# Load the trained models\n",
    "model_generic = tf.keras.models.load_model(\"model_generic.h5\")\n",
    "model_parallel_1 = tf.keras.models.load_model(\"model_parallel_1.h5\")\n",
    "model_parallel_2 = tf.keras.models.load_model(\"model_parallel_2.h5\")\n",
    "model_combined = tf.keras.models.load_model(\"model_combined.h5\")\n",
    "\n",
    "# Convert lists to numpy arrays for compatibility with TensorFlow\n",
    "X_input_generic = tf.constant([input_data_generic], dtype=tf.float32)\n",
    "X_input_parallel_1 = tf.constant([input_data_parallel_1], dtype=tf.float32)\n",
    "X_input_parallel_2 = tf.constant([input_data_parallel_2], dtype=tf.float32)\n",
    "\n",
    "# Make predictions using individual models\n",
    "predictions_generic = model_generic.predict(X_input_generic)\n",
    "predictions_parallel_1 = model_parallel_1.predict(X_input_parallel_1)\n",
    "predictions_parallel_2 = model_parallel_2.predict(X_input_parallel_2)\n",
    "\n",
    "# Combine the outputs of parallel AI 1 and AI 2 for the third AI\n",
    "combined_input = tf.keras.layers.Concatenate()([predictions_parallel_1, predictions_parallel_2])\n",
    "\n",
    "# Make predictions using the combined model\n",
    "predictions_combined = model_combined.predict(combined_input)\n",
    "\n",
    "your_original_labels_for_generic = ['Engineering']\n",
    "your_original_labels_for_parallel_1 = ['Computer Science and Engineering (including specializations) / Information Technology', 'Electronics and Communication Engineering', 'Mechanical Engineering']\n",
    "your_original_labels_for_parallel_2 = [ 'Computer Science and Engineering (including specializations) / Information Technology', 'Electronics and Communication Engineering', 'Mechanical Engineering', 'Civil Engineering']\n",
    "your_original_labels_for_combined = [ 'Computer Science and Engineering (including specializations) / Information Technology', 'Electronics and Communication Engineering', 'Mechanical Engineering', 'Civil Engineering']\n",
    "\n",
    "# Create and fit LabelEncoders for each model's predictions\n",
    "label_decoder_generic = LabelEncoder()\n",
    "label_decoder_generic.fit(your_original_labels_for_generic)  # Replace with your actual labels\n",
    "label_decoder_parallel_1 = LabelEncoder()\n",
    "label_decoder_parallel_1.fit(your_original_labels_for_parallel_1)  # Replace with your actual labels\n",
    "label_decoder_parallel_2 = LabelEncoder()\n",
    "label_decoder_parallel_2.fit(your_original_labels_for_parallel_2)  # Replace with your actual labels\n",
    "label_decoder_combined = LabelEncoder()\n",
    "label_decoder_combined.fit(your_original_labels_for_combined)  # Replace with your actual labels\n",
    "\n",
    "# Inverse transform the predictions to get the original labels\n",
    "predicted_labels_generic = label_decoder_generic.inverse_transform(tf.argmax(predictions_generic, axis=1).numpy())\n",
    "predicted_labels_parallel_1 = label_decoder_parallel_1.inverse_transform(tf.argmax(predictions_parallel_1, axis=1).numpy())\n",
    "predicted_labels_parallel_2 = label_decoder_parallel_2.inverse_transform(tf.argmax(predictions_parallel_2, axis=1).numpy())\n",
    "predicted_labels_combined = label_decoder_combined.inverse_transform(tf.argmax(predictions_combined, axis=1).numpy())\n",
    "\n",
    "# Print or use the predicted labels as needed\n",
    "print(\"Predicted Labels - Generic AI:\", predicted_labels_generic)\n",
    "print(\"Predicted Labels - Parallel AI 1:\", predicted_labels_parallel_1)\n",
    "print(\"Predicted Labels - Parallel AI 2:\", predicted_labels_parallel_2)\n",
    "print(\"Predicted Labels - Combined AI:\", predicted_labels_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a36be80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94fc6aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(55, 7), dtype=float32, numpy=\n",
       "array([[9.08665895e-01, 7.85072744e-02, 1.28267314e-02, 3.23375426e-02,\n",
       "        9.62293088e-01, 2.99334736e-03, 2.37603881e-03],\n",
       "       [4.40584630e-01, 5.12869239e-01, 4.65461239e-02, 1.29986137e-01,\n",
       "        8.17202806e-01, 4.22340818e-02, 1.05769988e-02],\n",
       "       [6.99215412e-01, 2.72508442e-01, 2.82760914e-02, 8.99858549e-02,\n",
       "        8.94770086e-01, 1.20007256e-02, 3.24325031e-03],\n",
       "       [7.77400851e-01, 2.21831277e-01, 7.67842401e-04, 1.06214974e-02,\n",
       "        9.77967381e-01, 9.87688918e-03, 1.53420400e-03],\n",
       "       [6.99751794e-01, 2.97398239e-01, 2.85005104e-03, 1.30574867e-01,\n",
       "        8.53596628e-01, 2.61842133e-03, 1.32102007e-02],\n",
       "       [9.44211662e-01, 4.08244245e-02, 1.49638383e-02, 3.01475823e-02,\n",
       "        8.62394989e-01, 1.03872173e-01, 3.58517421e-03],\n",
       "       [8.79166126e-01, 1.13772824e-01, 7.06104143e-03, 1.30582988e-01,\n",
       "        8.35585654e-01, 1.79549474e-02, 1.58765037e-02],\n",
       "       [2.19643191e-02, 5.69939911e-01, 4.08095777e-01, 2.17953861e-01,\n",
       "        7.76116014e-01, 5.47149801e-04, 5.38290897e-03],\n",
       "       [4.69841845e-02, 8.27502072e-01, 1.25513762e-01, 3.90617326e-02,\n",
       "        8.79570723e-01, 7.87021145e-02, 2.66534905e-03],\n",
       "       [6.33076668e-01, 3.59729052e-01, 7.19436165e-03, 1.22880504e-01,\n",
       "        8.71229053e-01, 3.57778138e-03, 2.31262576e-03],\n",
       "       [7.93820992e-02, 7.97311783e-01, 1.23306155e-01, 3.62196714e-02,\n",
       "        9.51269567e-01, 7.33654713e-03, 5.17422706e-03],\n",
       "       [2.66773611e-01, 6.22054577e-01, 1.11171812e-01, 1.06203482e-02,\n",
       "        9.51392889e-01, 3.58563103e-02, 2.13035126e-03],\n",
       "       [5.82998618e-02, 7.53802896e-01, 1.87897280e-01, 8.31922442e-02,\n",
       "        8.42348397e-01, 2.82461513e-02, 4.62132730e-02],\n",
       "       [2.14658439e-01, 7.71595299e-01, 1.37461564e-02, 1.44990399e-01,\n",
       "        8.31436872e-01, 1.16601177e-02, 1.19126225e-02],\n",
       "       [3.31145048e-01, 6.67647421e-01, 1.20765052e-03, 2.56275330e-02,\n",
       "        9.62705672e-01, 8.00119899e-03, 3.66567960e-03],\n",
       "       [8.31312239e-02, 9.13020253e-01, 3.84852337e-03, 2.31523484e-01,\n",
       "        7.33196676e-01, 8.31670407e-03, 2.69631669e-02],\n",
       "       [4.99006629e-01, 4.94262576e-01, 6.73075533e-03, 2.57891119e-01,\n",
       "        7.09763825e-01, 4.47945390e-03, 2.78657135e-02],\n",
       "       [2.87287116e-01, 7.07241356e-01, 5.47153875e-03, 2.32904013e-02,\n",
       "        9.70691741e-01, 3.95398727e-03, 2.06375169e-03],\n",
       "       [4.10899706e-02, 9.51868892e-01, 7.04109296e-03, 9.92956087e-02,\n",
       "        8.41367602e-01, 1.33447172e-02, 4.59919348e-02],\n",
       "       [2.63993859e-01, 6.50262594e-01, 8.57435614e-02, 1.85247902e-02,\n",
       "        9.54260886e-01, 1.78231504e-02, 9.39110760e-03],\n",
       "       [9.58780646e-01, 2.02909801e-02, 2.09283717e-02, 5.14466576e-02,\n",
       "        9.27018225e-01, 1.23287737e-02, 9.20646172e-03],\n",
       "       [8.80837977e-01, 1.11311585e-01, 7.85037037e-03, 6.07417636e-02,\n",
       "        8.97588015e-01, 2.03405432e-02, 2.13296134e-02],\n",
       "       [6.56437635e-01, 2.91501105e-01, 5.20612411e-02, 1.71686932e-01,\n",
       "        8.20625901e-01, 3.63417459e-03, 4.05311259e-03],\n",
       "       [2.35619605e-01, 7.58414924e-01, 5.96550293e-03, 3.33356187e-02,\n",
       "        9.44012165e-01, 1.86481159e-02, 4.00421908e-03],\n",
       "       [8.42894197e-01, 9.81668904e-02, 5.89389466e-02, 8.59952495e-02,\n",
       "        9.11295533e-01, 1.79447979e-03, 9.14690725e-04],\n",
       "       [2.89262056e-01, 6.68331444e-01, 4.24066037e-02, 7.93047398e-02,\n",
       "        9.09896493e-01, 8.63166712e-03, 2.16713012e-03],\n",
       "       [7.66080618e-01, 2.12336376e-01, 2.15830561e-02, 3.87679413e-02,\n",
       "        9.51028287e-01, 2.73170788e-03, 7.47209229e-03],\n",
       "       [7.33983994e-01, 2.58370012e-01, 7.64600933e-03, 8.90997797e-02,\n",
       "        8.60180974e-01, 3.03208027e-02, 2.03983616e-02],\n",
       "       [8.07493091e-01, 1.85740456e-01, 6.76646177e-03, 9.91639309e-03,\n",
       "        9.86878395e-01, 2.75287032e-03, 4.52254113e-04],\n",
       "       [6.52360678e-01, 3.37389857e-01, 1.02494489e-02, 8.80945846e-02,\n",
       "        8.96019220e-01, 2.81586219e-03, 1.30702714e-02],\n",
       "       [2.55790614e-02, 9.45557475e-01, 2.88634617e-02, 4.88885269e-02,\n",
       "        9.47874844e-01, 1.20936346e-03, 2.02725362e-03],\n",
       "       [5.20695932e-03, 9.32825327e-01, 6.19676784e-02, 1.22120464e-02,\n",
       "        9.56016243e-01, 2.98779439e-02, 1.89386727e-03],\n",
       "       [2.82727703e-02, 8.50399554e-01, 1.21327676e-01, 1.72624532e-02,\n",
       "        9.33114827e-01, 3.94517146e-02, 1.01709524e-02],\n",
       "       [2.00323910e-01, 7.93121278e-01, 6.55481778e-03, 1.23716965e-01,\n",
       "        8.71631444e-01, 1.58099830e-03, 3.07054585e-03],\n",
       "       [1.07127786e-01, 8.12145114e-01, 8.07271004e-02, 6.49231076e-01,\n",
       "        3.27114671e-01, 7.45522790e-04, 2.29086634e-02],\n",
       "       [3.48015763e-02, 9.29304957e-01, 3.58935595e-02, 2.20702793e-02,\n",
       "        9.59742010e-01, 1.40785044e-02, 4.10910510e-03],\n",
       "       [1.63154155e-02, 5.71613729e-01, 4.12070900e-01, 1.61635056e-01,\n",
       "        8.33495438e-01, 1.70969707e-03, 3.15989484e-03],\n",
       "       [5.47618389e-01, 2.82058507e-01, 1.70323059e-01, 1.28723651e-01,\n",
       "        7.60607898e-01, 7.41423368e-02, 3.65260839e-02],\n",
       "       [1.21312412e-02, 1.41539142e-01, 8.46329570e-01, 2.03634780e-02,\n",
       "        9.65811312e-01, 1.18007297e-02, 2.02456815e-03],\n",
       "       [3.55454581e-03, 1.33997172e-01, 8.62448394e-01, 6.05409086e-01,\n",
       "        3.34952474e-01, 1.38714514e-03, 5.82514182e-02],\n",
       "       [9.36665293e-03, 8.11946243e-02, 9.09438610e-01, 1.21781781e-01,\n",
       "        8.63070309e-01, 8.22539558e-04, 1.43252211e-02],\n",
       "       [1.00846058e-02, 7.56990388e-02, 9.14216340e-01, 4.94484603e-03,\n",
       "        9.65678930e-01, 2.79140789e-02, 1.46202836e-03],\n",
       "       [1.05158631e-02, 4.51426506e-02, 9.44341481e-01, 3.06492671e-02,\n",
       "        9.52928007e-01, 5.57616306e-03, 1.08465096e-02],\n",
       "       [3.85232195e-02, 7.51374587e-02, 8.86339307e-01, 7.47521520e-02,\n",
       "        9.19198453e-01, 4.26661130e-03, 1.78271311e-03],\n",
       "       [1.02557279e-02, 1.18534803e-01, 8.71209502e-01, 6.01063259e-02,\n",
       "        8.10053349e-01, 1.14063576e-01, 1.57766510e-02],\n",
       "       [8.21024001e-01, 1.72698349e-01, 6.27770415e-03, 3.62736848e-03,\n",
       "        9.76038933e-01, 1.98970456e-02, 4.36520932e-04],\n",
       "       [2.09400952e-02, 7.47363567e-01, 2.31696412e-01, 3.13168913e-02,\n",
       "        8.93835068e-01, 6.37686998e-02, 1.10793207e-02],\n",
       "       [8.37437093e-01, 1.22595742e-01, 3.99670452e-02, 1.65612418e-02,\n",
       "        9.61496353e-01, 1.40591171e-02, 7.88332894e-03],\n",
       "       [2.63024308e-02, 4.66375574e-02, 9.27060008e-01, 9.49458685e-03,\n",
       "        9.87054944e-01, 2.88116327e-03, 5.69261378e-04],\n",
       "       [5.93571723e-01, 4.01800781e-01, 4.62744292e-03, 2.35832613e-02,\n",
       "        9.74084735e-01, 1.23765646e-03, 1.09444791e-03],\n",
       "       [7.75075912e-01, 2.12654769e-01, 1.22693004e-02, 5.33225425e-02,\n",
       "        1.61613822e-02, 4.37258137e-03, 9.26143527e-01],\n",
       "       [1.02587575e-02, 8.83845508e-01, 1.05895728e-01, 8.84362906e-02,\n",
       "        5.54334046e-03, 5.88421058e-03, 9.00136113e-01],\n",
       "       [2.51389652e-01, 7.24338472e-01, 2.42718793e-02, 1.32480979e-01,\n",
       "        1.45861097e-02, 7.78777990e-03, 8.45145166e-01],\n",
       "       [7.93490373e-03, 7.65193403e-02, 9.15545702e-01, 5.06174453e-02,\n",
       "        2.58220118e-02, 9.71702952e-03, 9.13843453e-01],\n",
       "       [2.66948771e-02, 3.96206409e-01, 5.77098727e-01, 4.81498986e-02,\n",
       "        3.30415694e-03, 6.49699767e-04, 9.47896302e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3626537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate random data for 10 entries with values between 0 and 1\n",
    "data = np.random.rand(10, 8)\n",
    "\n",
    "# Create a DataFrame with the generated data\n",
    "df = pd.DataFrame(data, columns=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "# Calculate the maximum value in columns 0, 1, 2, and assign it to column 0\n",
    "df[3] = df[[0, 1, 2, 3]].max(axis=1)\n",
    "\n",
    "# Calculate the maximum value in columns 3, 4, 5, and assign it to column 3\n",
    "df[7] = df[[4, 5, 6, 7]].max(axis=1)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"generated_data1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dd8cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
